{
  "hash": "86e58f023535740e0b1c80ed552b2775",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercice 4\"\nauthor: \"Authors.s\"\ndate: \"2025-04-xx\"\ndate-modified: \"2025-04-06\"\nformat: \n  html:\n    embed-resources: false\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    toc-location: right\n    page-layout: article\n    code-overflow: wrap\ntoc: true\nnumber-sections: false\neditor: visual\ncategories: [\"categorie 1\", \"cotegorie 2\"]\nimage: \"\"\ndescription: \"Description\"\n---\n\n\n\n# Intervenant.e.s\n\n### Rédaction\n\n-   **Clément Poupelin**, [clementjc.poupelin\\@gmail.com](mailto:clementjc.poupelin@gmail.com){.email}\\\n\n### Relecture\n\n-   \n\n# Setup\n\n:::: panel-tabset\n## Packages\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Fonctions\n\n::: panel-tabset\n\n### Coefficients MCO\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta1_MCO <- function(x, y) {\n  sum((x - mean(x)) * (y - mean(y))) / sum((x - mean(x))^2)\n}\n\nbeta0_MCO <- function(x, y) {\n  mean(y) - beta1_MCO(x, y) * mean(x)\n}\n```\n:::\n\n\n\n### Coefficients RI\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta1_RI <- function(x, y) {\n  sum((y - mean(y))^2) / sum((x - mean(x)) * (y - mean(y)))\n}\n\nbeta0_RI <- function(x, y) {\n  mean(y) - beta1_RI(x, y) * mean(x)\n}\n```\n:::\n\n\n\n:::\n\n## Seed\n::::\n\n# Données\n\nOn va illustrer par des simulations les propriétés des estimateurs des coefficients de la régression simple par la méthode MCO et par la méthode inverse.\n\nPour cela on fera sur deux parties disticntes :\n\n  - **Partie 1** : iniiation à l'estimation des coefficients de régression via des fonctions construites \"à la main\"\n  \n  - **Partie 2** : utilisation de la fonction *`lm`* pour l'estimation des coefficients de régression\n\n\n::: panel-tabset\n\n## Partie 1\n\nOn considère deux échantillons de $n$ variables $(X_1, . . . , X_n)$ et $(Y_1, . . . , Y_n)$. On suppose que les $(X_1, . . . , X_n)$ sont connus. On considère le modèle de régression simple\n$$Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i$$\noù les $\\varepsilon_i$ sont i.i.d de moyenne nulle, non corrélées et de variance $\\sigma^2$ .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\ndata <- readr::read_csv(\"../Data/X.txt\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\nRows: 100 Columns: 2\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n(2): ...1, x\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n\n\n:::\n\n```{.r .cell-code}\nbeta1 = 2\nbeta0 = 10\n\n\n# On créer une variable epsilon que l'on complète de 100 valeurs (taille de X)\n# qui sont des observation obtenue suivant une loi gaussienne (0, 1)\ndata$epsilon <- rnorm(100, 0, 1)\n\n# on construit la variable des Yi\ndata$Y = 10 + 2*data$x + data$epsilon\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# on fait nos estimateur MCO inverses\nbeta1_RI(data$x, 10 + 2*data$x + rnorm(100, 0, 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.373566\n```\n\n\n:::\n\n```{.r .cell-code}\nbeta0_RI(as.numeric(data$x), as.numeric(10 + 2*data$x + rnorm(100, 0, 1)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.899487\n```\n\n\n:::\n\n```{.r .cell-code}\n#> beta1RI(as.numeric(data$x), as.numeric(data$Y))\n#[1] 2.500503\n#> beta0RI(as.numeric(data$x), as.numeric(data$Y))\n#[1] 9.892161\n\n\nbeta1_MCO(as.numeric(data$x), as.numeric(data$Y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.981214\n```\n\n\n:::\n\n```{.r .cell-code}\nbeta0_MCO(as.numeric(data$x), as.numeric(data$Y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.997608\n```\n\n\n:::\n\n```{.r .cell-code}\n#> beta1MCO(as.numeric(data$x), as.numeric(data$Y))\n#[1] 1.843383\n#> beta0MCO(as.numeric(data$x), as.numeric(data$Y))\n#[1] 9.89286\n\n\n\n## nos esimateurs sont pas loin des beta1 et beta0\n\n\ndata$B1RI = 0\ndata$B0RI = 0\n\nfor (i in 1:100){\n  data$B1RI[i] = beta1_RI(data$x, 10 + 2*data$x + rnorm(100, 0, 1))\n  \n  data$B0RI[i] = beta0_RI(as.numeric(data$x), as.numeric(10 + 2*data$x + rnorm(100, 0, 1)))\n  \n}\n\n\ndata$B1MCO = 0\ndata$B0MCO = 0\n\nfor (i in 1:100){\n  data$B1MCO[i] = beta1_MCO(data$x, 10 + 2*data$x + rnorm(100, 0, 1))\n  \n  data$B0MCO[i] = beta0_MCO(as.numeric(data$x), as.numeric(10 + 2*data$x + rnorm(100, 0, 1)))\n  \n}\n\n\nboxplot(data$B0RI, data$B0MCO,\n        main = \"Estimation de Beta0 avec une erreur ~N(0,1)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B0RI\", \"B0MCO\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE) \nabline(v = 10, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(data$B1RI, data$B1MCO,\n        main = \"Estimation de Beta1 avec une erreur ~N(0,1)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B1RI\", \"B1MCO\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE)\nabline(v = 2, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n########### Question 6) ##############\n\ndata$B1RI2 = 0\ndata$B0RI2 = 0\n\nfor (i in 1:100){\n  data$B1RI2[i] = beta1_RI(data$x, 10 + 2*data$x + rnorm(100, 0, 16))\n  \n  data$B0RI2[i] = beta0_RI(as.numeric(data$x), as.numeric(10 + 2*data$x + rnorm(100, 0, 16)))\n  \n}\n\n\ndata$B1MCO2 = 0\ndata$B0MCO2 = 0\n\nfor (i in 1:100){\n  data$B1MCO2[i] = beta1_MCO(data$x, 10 + 2*data$x + rnorm(100, 0, 16))\n  \n  data$B0MCO2[i] = beta0_MCO(as.numeric(data$x), as.numeric(10 + 2*data$x + rnorm(100, 0, 16)))\n  \n}\n\n\nboxplot(data$B0RI2, data$B0MCO2,\n        main = \"Estimation de Beta0 avec une erreur ~N(0,16)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B0RI\", \"B0MCO\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(data$B1RI2, data$B1MCO2,\n        main = \"Estimation de Beta1 avec une erreur ~N(0,16)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B1RI\", \"B1MCO\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n```{.r .cell-code}\n########### Question 5) Corrigé ##############\n\n\n\nB = 10000\nn = length(data$x); n\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 100\n```\n\n\n:::\n\n```{.r .cell-code}\nres = matrix(0, ncol=4, nrow=B)\ndim(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000     4\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (b in 1:B){\n  eps = rnorm(n)\n  y = 10 + 2 * data$x + eps\n  res[b,] = c(beta1_MCO(data$x, y), beta0_MCO(data$x, y), beta1_RI(data$x, y), beta0_RI(data$x, y))\n\n}\n\nboxplot(res[,c(1,3)], \n        main = 'Comparaison des pentes', \n        names = c('MCO', 'RI'))\nabline(h = 2, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#### faire apparaitre biais et variance ####\n\n# calcul du biais \n\nbiaisbeta1MCO = mean(res[,1] - 2)\nvariancebeta1MCO = (1/B) * sum((res[,1] - 2)**2)\n\nbiaisbeta0MCO = (1/B) * sum(res[,2] - 2)\nvariancebeta0MCO = (1/B) * sum((res[,2] - 2)**2)\n\nbiaisbeta1RI = (1/B) * sum(res[,3] - 2)\nvariancebeta1RI = (1/B) * sum((res[,3] - 2)**2)\n\nbiaisbeta0RI = (1/B) * sum(res[,4] - 2)\nvariancebeta0RI = (1/B) * sum((res[,4] - 2)**2)\n\n\nbiaisbeta1MCO\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.001831563\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 0.0007703197\n\nvariancebeta1MCO\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01020028\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 0.01003526\n\nbiaisbeta0MCO\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7.999682\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 7.999521\n\nvariancebeta0MCO\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 64.00522\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 64.00262\n\nbiaisbeta1RI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4985279\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 0.4995708\n\nvariancebeta1RI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2591415\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 0.2605581\n\nbiaisbeta0RI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7.946946\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 7.946902\n\nvariancebeta0RI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 63.16427\n```\n\n\n:::\n\n```{.r .cell-code}\n#[1] 63.16354\n\n\n#####\n\n\nboxplot(res[,c(2,4)],\n        main = \"Estimation de Beta0 avec une erreur ~N(0,1)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B0MCO\", \"B0RI\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE) \nabline(v = 10, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-6.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(res[,c(1,3)],\n        main = \"Estimation de Beta1 avec une erreur ~N(0,1)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B1MCO\", \"B1RI\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE)\nabline(v = 2, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-7.png){width=672}\n:::\n\n```{.r .cell-code}\n## On voit que c'est des estimateurs sans biais \n\n\n########### Question 6) Corrigé ##############\n\n\nres2 = matrix(0, ncol=4, nrow=B)\n\n\nfor (b in 1:B){\n  eps = rnorm(n, 0, 16)\n  y = 10 + 2 * data$x + eps\n  res2[b,] = c(beta1_MCO(data$x, y), beta0_MCO(data$x, y), beta1_RI(data$x, y), beta0_RI(data$x, y))\n}\n\n\nboxplot(res2[,c(2,4)],\n        main = \"Estimation de Beta0 avec une erreur ~N(0,16)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B0MCO\", \"B0RI\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE) \nabline(v = 10, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-8.png){width=672}\n:::\n\n```{.r .cell-code}\nboxplot(res2[,c(1,3)],\n        main = \"Estimation de Beta1 avec une erreur ~N(0,16)\",\n        xlab = \"xlab\",\n        #ylab = \"\",\n        names = c(\"B1RI\", \"B1MCO\"),\n        col = c(\"purple\",\"pink\"),\n        border = \"brown\",\n        horizontal = TRUE,\n        notch = TRUE)\nabline(v = 2, col = 2)\n```\n\n::: {.cell-output-display}\n![](Exercice_01.04_files/figure-html/unnamed-chunk-4-9.png){width=672}\n:::\n:::\n\n\n\n\n## Partie 2\n\n:::\n\n\n\n# Analyse\n\n::: callout-note\nMETTRE LES REMARQUES\n:::\n\n::: callout-warning\nMETTRE LES POINTS D'ATTENTION\n:::\n\n:::: success-header\n::: success-icon\n:::\n\nRésultats\n::::\n\n::: success\nMETTRE LES CONCLUSIONS\n:::\n\n# Conclusion\n\n# Session info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sessioninfo::session_info(pkgs = \"attached\")\n```\n:::\n\n\n",
    "supporting": [
      "Exercice_01.04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}